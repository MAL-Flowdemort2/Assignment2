{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "dprjojsGY5xR"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import layers\n",
        "from keras import ops\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWAcuYg1Y8n1",
        "outputId": "de66b9fc-5f86-4233-c59b-62575932253a"
      },
      "outputs": [],
      "source": [
        "X = np.load('data/x_letters.npy')\n",
        "y = np.load('data/y_letters.npy')\n",
        "\n",
        "num_classes = 26\n",
        "\n",
        "y = to_categorical(y, num_classes=num_classes)  # One-hot encode labels,\n",
        "\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    X, y, test_size=0.4, random_state=42\n",
        ")\n",
        "\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42\n",
        ")\n",
        "X_train, X_test, X_val = X_train / 255.0, X_test / 255.0, X_val / 255.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def number_to_letter(number):\n",
        "    if 0 <= number <= 25:\n",
        "        return chr(number + 65)  # ASCII value of 'A' is 65, so we add 65 to the number.\n",
        "    else:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "E\n"
          ]
        }
      ],
      "source": [
        "plt.imshow(X_train[0])\n",
        "plt.show()\n",
        "\n",
        "letter = number_to_letter(np.array(y_train[0]).argmax())\n",
        "print(y_train[0])\n",
        "print(letter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CGAN implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "dPbY4JVDY9fr"
      },
      "outputs": [],
      "source": [
        "#Source: https://keras.io/examples/generative/dcgan_overriding_train_step/\n",
        "\n",
        "class GAN(keras.Model):\n",
        "    def __init__(self, discriminator, generator, latent_dim):\n",
        "        super().__init__()\n",
        "        self.discriminator = discriminator\n",
        "        self.generator = generator\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def compile(self, d_optimizer, g_optimizer, loss_fn):\n",
        "        super().compile()\n",
        "        self.d_optimizer = d_optimizer\n",
        "        self.g_optimizer = g_optimizer\n",
        "        self.loss_fn = loss_fn\n",
        "        self.d_loss_metric = keras.metrics.Mean(name=\"d_loss\")\n",
        "        self.g_loss_metric = keras.metrics.Mean(name=\"g_loss\")\n",
        "\n",
        "    @property\n",
        "    def metrics(self):\n",
        "        return [self.d_loss_metric, self.g_loss_metric]\n",
        "\n",
        "    def train_step(self, real_images):\n",
        "        # Sample random points in the latent space\n",
        "        batch_size = ops.shape(real_images)[0]\n",
        "        random_latent_vectors = keras.random.normal(\n",
        "            shape=(batch_size, self.latent_dim)\n",
        "        )\n",
        "\n",
        "        # Decode them to fake images\n",
        "        generated_images = self.generator(random_latent_vectors)\n",
        "\n",
        "        # Combine them with real images\n",
        "        combined_images = ops.concatenate([generated_images, real_images], axis=0)\n",
        "\n",
        "        # Assemble labels discriminating real from fake images\n",
        "        labels = ops.concatenate(\n",
        "            [ops.ones((batch_size, 1)), ops.zeros((batch_size, 1))], axis=0\n",
        "        )\n",
        "        # Add random noise to the labels - important trick!\n",
        "        #basically makes sure the discriminator is not perfect,\n",
        "        #so that the generator never has a chance to learn\n",
        "        labels += 0.05 * tf.random.uniform(tf.shape(labels))\n",
        "\n",
        "        # Train the discriminator\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(combined_images)\n",
        "            d_loss = self.loss_fn(labels, predictions)\n",
        "        grads = tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
        "        self.d_optimizer.apply_gradients(\n",
        "            zip(grads, self.discriminator.trainable_weights)\n",
        "        )\n",
        "\n",
        "        # Sample random points in the latent space\n",
        "        random_latent_vectors = keras.random.normal(\n",
        "            shape=(batch_size, self.latent_dim)\n",
        "        )\n",
        "\n",
        "        # Assemble labels that say \"all real images\"\n",
        "        misleading_labels = ops.zeros((batch_size, 1))\n",
        "\n",
        "        # Train the generator (note that we should *not* update the weights\n",
        "        # of the discriminator)!\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
        "            g_loss = self.loss_fn(misleading_labels, predictions)\n",
        "        grads = tape.gradient(g_loss, self.generator.trainable_weights)\n",
        "        self.g_optimizer.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
        "\n",
        "        # Update metrics\n",
        "        self.d_loss_metric.update_state(d_loss)\n",
        "        self.g_loss_metric.update_state(g_loss)\n",
        "        return {\n",
        "            \"d_loss\": self.d_loss_metric.result(),\n",
        "            \"g_loss\": self.g_loss_metric.result(),\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "cJQeQPgYZBmw"
      },
      "outputs": [],
      "source": [
        "def plot_string(string, generator, latent_dim):\n",
        "    pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1HsOLomZGaG",
        "outputId": "d330c287-3836-43c1-9c48-10810da19a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 5ms/step - d_loss: 0.6751 - g_loss: 0.8149\n",
            "Epoch 2/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.6328 - g_loss: 0.9333\n",
            "Epoch 3/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.5811 - g_loss: 1.0901\n",
            "Epoch 4/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.5469 - g_loss: 1.1940\n",
            "Epoch 5/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.5160 - g_loss: 1.2482\n",
            "Epoch 6/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.4973 - g_loss: 1.2865\n",
            "Epoch 7/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.4802 - g_loss: 1.2969\n",
            "Epoch 8/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.4636 - g_loss: 1.3033\n",
            "Epoch 9/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.4524 - g_loss: 1.2824\n",
            "Epoch 10/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.4328 - g_loss: 1.2952\n",
            "Epoch 11/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.4214 - g_loss: 1.2598\n",
            "Epoch 12/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.4076 - g_loss: 1.2283\n",
            "Epoch 13/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.3954 - g_loss: 1.2031\n",
            "Epoch 14/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.3861 - g_loss: 1.1790\n",
            "Epoch 15/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.3715 - g_loss: 1.1210\n",
            "Epoch 16/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.3629 - g_loss: 1.0731\n",
            "Epoch 17/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.3470 - g_loss: 1.0424\n",
            "Epoch 18/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.3375 - g_loss: 0.9838\n",
            "Epoch 19/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.3268 - g_loss: 0.9233\n",
            "Epoch 20/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.3168 - g_loss: 0.8942\n",
            "Epoch 21/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.3045 - g_loss: 0.8671\n",
            "Epoch 22/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2992 - g_loss: 0.8173\n",
            "Epoch 23/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2825 - g_loss: 0.7811\n",
            "Epoch 24/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2781 - g_loss: 0.7382\n",
            "Epoch 25/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2692 - g_loss: 0.7228\n",
            "Epoch 26/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2607 - g_loss: 0.6890\n",
            "Epoch 27/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2546 - g_loss: 0.6454\n",
            "Epoch 28/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2446 - g_loss: 0.6313\n",
            "Epoch 29/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2374 - g_loss: 0.6080\n",
            "Epoch 30/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2321 - g_loss: 0.5722\n",
            "Epoch 31/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2280 - g_loss: 0.5686\n",
            "Epoch 32/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2162 - g_loss: 0.5491\n",
            "Epoch 33/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2096 - g_loss: 0.5178\n",
            "Epoch 34/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.2081 - g_loss: 0.5175\n",
            "Epoch 35/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1966 - g_loss: 0.5195\n",
            "Epoch 36/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1961 - g_loss: 0.4968\n",
            "Epoch 37/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1919 - g_loss: 0.4865\n",
            "Epoch 38/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1874 - g_loss: 0.4811\n",
            "Epoch 39/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1809 - g_loss: 0.4735\n",
            "Epoch 40/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1773 - g_loss: 0.4705\n",
            "Epoch 41/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1751 - g_loss: 0.4550\n",
            "Epoch 42/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1669 - g_loss: 0.4606\n",
            "Epoch 43/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1654 - g_loss: 0.4628\n",
            "Epoch 44/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1626 - g_loss: 0.4549\n",
            "Epoch 45/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1582 - g_loss: 0.4271\n",
            "Epoch 46/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1560 - g_loss: 0.4371\n",
            "Epoch 47/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1509 - g_loss: 0.4325\n",
            "Epoch 48/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1493 - g_loss: 0.4617\n",
            "Epoch 49/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1463 - g_loss: 0.4258\n",
            "Epoch 50/50\n",
            "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - d_loss: 0.1433 - g_loss: 0.4400\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a4f6958d990>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dc_latent_dim = 100\n",
        "\n",
        "dcgenerator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(dc_latent_dim,)),\n",
        "        layers.Dense(7*7*128),\n",
        "        layers.Reshape([7, 7, 128]), #128 feature maps of 7*7\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2DTranspose(64, kernel_size = 5, strides = 2, padding = \"same\", activation = \"relu\"), #strides = 2 -> 14*14 maps - 64 of them\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2DTranspose(1, kernel_size = 5, strides = 2, padding = \"same\", activation = \"tanh\") #1 image of size 28*28\n",
        "    ],\n",
        "    name=\"dcgenerator\",\n",
        ")\n",
        "\n",
        "dcdiscriminator = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(64, kernel_size = 5, strides = 2, padding = \"same\", activation = layers.LeakyReLU(0.2)), #strided convolution\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Conv2D(128, kernel_size = 5, strides = 2, padding = \"same\", activation = layers.LeakyReLU(0.2)),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ],\n",
        "    name=\"dcdiscriminator\",\n",
        ")\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "dcgan = GAN(discriminator=dcdiscriminator, generator=dcgenerator, latent_dim=dc_latent_dim)\n",
        "dcgan.compile(\n",
        "    d_optimizer=keras.optimizers.RMSprop(learning_rate=0.0005),\n",
        "    g_optimizer=keras.optimizers.RMSprop(learning_rate=0.003),\n",
        "    loss_fn=keras.losses.BinaryCrossentropy(),\n",
        ")\n",
        "\n",
        "X_train_dcgan = (X_train.reshape(-1, 28, 28, 1) * 2. - 1.) #btwn -1 and 1 - to match tanh output\n",
        "\n",
        "dcgan.fit(X_train_dcgan, epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mexKFCBrbXp3"
      },
      "source": [
        "A problem you often encounter when training DCGANs is that you get locally convincing features but overall inconsistensies - here, you can see a \"classic\": Shirts with one long and one short sleeve."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
